{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMM1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mok0na/projet-tc4/blob/master/HMM1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KwZuJKZufUSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Chargement des données"
      ]
    },
    {
      "metadata": {
        "id": "injWPZSXfune",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. importation des données"
      ]
    },
    {
      "metadata": {
        "id": "u-QJKW-vcraw",
        "colab_type": "code",
        "outputId": "3297145a-e909-4dcf-cfe9-7c11bba86163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pickle\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# import dataset\n",
        "data_path ='/content/gdrive/My Drive/S5/TC4/projet-tc4/typos-data/'\n",
        "train10 = pickle.load(open(data_path + 'train10.pkl','rb'))\n",
        "test10 = pickle.load(open(data_path + 'test10.pkl','rb'))\n",
        "train20 = pickle.load(open(data_path + 'train20.pkl','rb'))\n",
        "test20 = pickle.load(open(data_path + 'test20.pkl','rb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ni1HnZBGhBVD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. obtention des états et observations"
      ]
    },
    {
      "metadata": {
        "id": "ljcscWBthADp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_states_observations(data):\n",
        "    observations = []\n",
        "    states = []\n",
        "    for sentence in data :\n",
        "        for w in sentence:\n",
        "            observations.append(w[0])\n",
        "            states.append(w[1])\n",
        "    observation_list = list(set(observations))\n",
        "    state_list = list(set(states))\n",
        "    return state_list,observation_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZt5-OIyhv0j",
        "colab_type": "code",
        "outputId": "e29076e6-b64a-41b6-b3ae-78b012a78050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "state_list,observation_list = get_states_observations(train)\n",
        "\n",
        "print(\"states :\\n\", state_list)\n",
        "print(\"observations :\\n\", observation_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "states :\n",
            " ['w', 'g', 'v', 'i', 'm', 'c', 'l', 'k', 'y', 'h', 'e', 'r', 'x', 's', 'p', 'f', 'n', 'z', 'd', 'j', 'o', 'b', 'u', 'q', 't', 'a']\n",
            "observations :\n",
            " ['w', 'g', 'v', 'i', 'm', 'c', 'l', 'k', 'y', 'h', 'e', 'r', 'x', 's', 'p', 'f', 'n', 'z', 'd', 'j', 'o', 'b', 'u', 'q', 't', 'a']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WM89O3esj9Sz",
        "colab_type": "code",
        "outputId": "0a28f545-92f2-4690-f330-37f4b2176010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('b', 'b'), ('y', 'y')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cpcOYgv_emxv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# I - HMM d'ordre 1\n",
        "\n",
        "**Dry run**: \n",
        "\n",
        "Train a first-order HMM using the training data. This is basically what we did in lab sessions for POS-tagging. Compute the error rate (at the character level) and compare this results with the dummiest classifier that just do nothing. You can also compute the number of errors your model can correct and the number of errors your model creates.\n",
        "\n",
        "## 1. implémentation"
      ]
    },
    {
      "metadata": {
        "id": "0BJC0hFBiF-0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "class HMM1:\n",
        "        def __init__(self, state_list, observation_list,\n",
        "                 transition_proba = None,\n",
        "                 observation_proba = None,\n",
        "                 initial_state_proba = None,\n",
        "                 epsilon = 1e-16):\n",
        "            \"\"\"Builds a new Hidden Markov Model\n",
        "            state_list is the list of state symbols [q_0...q_(N-1)]\n",
        "            observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
        "            transition_proba is the transition probability matrix\n",
        "                [a_ij] a_ij = Pr(Y_(t+1)=q_i|Y_t=q_j)\n",
        "            observation_proba is the observation probablility matrix\n",
        "                [b_ki] b_ki = Pr(X_t=v_k|Y_t=q_i)\n",
        "            initial_state_proba is the initial state distribution\n",
        "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
        "            print(\"HMM creating with: \")\n",
        "            self.N = len(state_list) # The number of states\n",
        "            self.M = len(observation_list) # The number of words in the vocabulary\n",
        "            print(str(self.N)+\" states\")\n",
        "            print(str(self.M)+\" observations\")\n",
        "            self.omega_Y = state_list # Keep the vocabulary of tags\n",
        "            self.omega_X = observation_list # Keep the vocabulary of tags\n",
        "            self.epsilon = epsilon\n",
        "            # Init. of the 3 distributions : observation, transition and initial states\n",
        "            if transition_proba is None:\n",
        "                self.transition_proba = np.zeros((self.N, self.N), np.float64) \n",
        "            else:\n",
        "                self.transition_proba=transition_proba\n",
        "            if observation_proba is None:\n",
        "                self.observation_proba = np.zeros((self.M, self.N), np.float) \n",
        "            else:\n",
        "                self.observation_proba=observation_proba\n",
        "            if initial_state_proba is None:\n",
        "                self.initial_state_proba = np.zeros((self.N,), np.float) \n",
        "            else:\n",
        "                self.initial_state_proba=initial_state_proba\n",
        "            # Since everything will be stored in numpy arrays, it is more convenient and compact to \n",
        "            # handle words and tags as indices (integer) for a direct access. However, we also need \n",
        "            # to keep the mapping between strings (word or tag) and indices. \n",
        "            self.make_indexes()\n",
        "\n",
        "        def make_indexes(self):\n",
        "            \"\"\"Creates the reverse table that maps states/observations names\n",
        "            to their index in the probabilities arrays\"\"\"\n",
        "            self.Y_index = {}\n",
        "            for i in range(self.N):\n",
        "                self.Y_index[self.omega_Y[i]] = i\n",
        "            self.X_index = {}\n",
        "            for i in range(self.M):\n",
        "                self.X_index[self.omega_X[i]] = i\n",
        "                \n",
        "        def get_X_index(self,observation):\n",
        "            index = 0\n",
        "            if observation in self.X_index:\n",
        "                index = self.X_index[observation]\n",
        "            return index\n",
        "      \n",
        "        def convert_Y_indexes_to_string(self,indexes):\n",
        "            strings = []\n",
        "            for ind in indexes:\n",
        "                strings.append(self.omega_Y[ind])\n",
        "            return np.array(strings)\n",
        "          \n",
        "        def counts(self,data):\n",
        "            transition_count = np.zeros((self.N, self.N), float)\n",
        "            observation_count = np.zeros((self.M, self.N), float)\n",
        "            initial_state_count = np.zeros((self.N), float)\n",
        "            emission_count = np.zeros((self.N, self.N), float)\n",
        "            for sentence in data:\n",
        "                for i,w in enumerate(sentence):\n",
        "                    # w[0] = observation w[1] = state\n",
        "                    observation_count[self.get_X_index(w[0]),self.Y_index[w[1]]] +=1\n",
        "                    if (i==0):\n",
        "                        initial_state_count[self.Y_index[w[1]]] +=1\n",
        "                    else :\n",
        "                        transition_count[self.Y_index[w[1]],self.Y_index[old_w1]] +=1\n",
        "                    old_w1 = w[1]\n",
        "            return transition_count, observation_count, initial_state_count\n",
        "        \n",
        "        #écrire 3 fonctions qui estimes les paramètres à partir des comptes, une fonction par distribution: observation, transition, état initial.\n",
        "        def estimate_observation(self,observation_count):\n",
        "            for i in range(len(observation_count[0])) :\n",
        "                self.observation_proba[:,i] = observation_count[:,i] + self.epsilon\n",
        "            self.observation_proba /= np.sum(self.observation_proba,axis=0)\n",
        "            \n",
        "        def estimate_transition(self,transition_count):\n",
        "            for i in range(len(transition_count[0])) :\n",
        "                self.transition_proba[:,i] = transition_count[:,i] + self.epsilon\n",
        "            self.transition_proba /= np.sum(self.transition_proba,axis=0)\n",
        "            \n",
        "        def estimate_initial_state(self,initial_state_count):\n",
        "            self.initial_state_proba = initial_state_count + self.epsilon\n",
        "            self.initial_state_proba /= np.sum(self.initial_state_proba,axis=0)\n",
        "        #écrire une fonction qui reprend le tout et qui estime tous les paramètres du HMM\n",
        "        def supervised_training(self, data) :\n",
        "\n",
        "            # Création de tous les comptes nécessaires pour l'estimation des paramètres du HMM\n",
        "            transition_count, observation_count, initial_state_count = self.counts(data)\n",
        "\n",
        "            # Estimation des paramètres à partir des comptes\n",
        "            self.estimate_observation(observation_count)\n",
        "            self.estimate_transition(transition_count)\n",
        "            self.estimate_initial_state(initial_state_count)\n",
        "            print(\"... Supervised training ...\")\n",
        "          \n",
        "        def forward(self, observation):\n",
        "            obs_seq = [self.get_X_index(w) for w in observation]\n",
        "            K = len(observation)\n",
        "            alpha = np.zeros((self.N, K), float)\n",
        "            # init\n",
        "            alpha[:,0] = self.obs_proba[:,obs_seq[0]] * self.initial_state_proba\n",
        "            # loop\n",
        "            for k in range(1,K):\n",
        "                for i in range(self.N):\n",
        "                    alpha[i,k] = np.dot(alpha[:,k-1], self.transition_proba[:,i] * self.observation_proba[obs_seq[k],i])\n",
        "            return alpha\n",
        "          \n",
        "        def backward(self, observation):\n",
        "            obs_seq = [self.get_X_index(w) for w in observation]\n",
        "            K = len(observation)\n",
        "            beta = np.zeros((self.N, K), float)\n",
        "            # init\n",
        "            beta[:,K-1] = 1\n",
        "            # loop\n",
        "            for k in range(K-2,-1,-1):\n",
        "                for i in range(N):\n",
        "                    beta[i,k] = np.sum(beta[:,k+1] * self.transition_proba[:,i] * self.observation_proba[obs_seq[k+1],i])\n",
        "            return beta                    \n",
        "              \n",
        "        def viterbi(self, observation):\n",
        "            \"\"\"\n",
        "            \"\"\"\n",
        "            obs_seq = [self.get_X_index(w) for w in observation]\n",
        "            K = len(observation)\n",
        "            delta = np.zeros((self.N,K), float)\n",
        "            psi = np.zeros((self.N,K-1), int)\n",
        "            # init\n",
        "            delta[:,0] =  self.initial_state_proba * self.observation_proba[obs_seq[0]]\n",
        "            # loop\n",
        "            for k in range(K-1):\n",
        "                tmp =self.transition_proba * delta[:,k]\n",
        "                delta[:,k+1] = self.observation_proba[obs_seq[k+1]] * np.max(tmp,axis=1)\n",
        "                psi[:,k] = np.argmax(tmp,axis=1)\n",
        "            states_seq = []\n",
        "            states_seq.append(np.argmax(delta[:,K-1],axis=0))\n",
        "            for k in range(K-1):\n",
        "                states_seq.insert(0,psi[states_seq[0],K-2-k])\n",
        "            #print(\"observation\",observation)\n",
        "            #print(\"states_seq\",states_seq)\n",
        "            return self.convert_Y_indexes_to_string(states_seq)\n",
        "        \n",
        "        def score(self,data,algo=\"viterbi\"):\n",
        "            \"\"\" \n",
        "            Caracter level\n",
        "            \"\"\"\n",
        "            pred_y = []\n",
        "            true_y = []\n",
        "            n_added_errors = 0\n",
        "            n_corrected = 0\n",
        "            total = 0\n",
        "            X = np.array([np.array([w[0] for w in sentence]) for sentence in data])\n",
        "            y = np.array([np.array([w[1] for w in sentence]) for sentence in data])\n",
        "            for i in range(len(X)):\n",
        "                if (algo == \"viterbi\"):\n",
        "                    predicted_y = self.viterbi(X[i])\n",
        "                if (algo == \"dummy\"):\n",
        "                    predicted_y = X[i]\n",
        "                pred_y.extend(predicted_y)\n",
        "                true_y.extend(y[i])\n",
        "                n_corrected += np.sum((X[i] != y[i]) * (y[i] == predicted_y),axis=0)\n",
        "                n_added_errors += np.sum((X[i] == y[i]) *(y[i] != predicted_y),axis=0)\n",
        "                total += len(X[i])\n",
        "            print(\"=======================SCORES with {}========================\".format(algo))\n",
        "            print(\"error rate {:.2f}%\".format(100-100*sklearn.metrics.accuracy_score(true_y,pred_y)))\n",
        "            print(\"precision {:.2f}%\".format(100*sklearn.metrics.precision_score(true_y,pred_y,labels=state_list,average='weighted')))\n",
        "            print(\"recall {:.2f}%\".format(100*sklearn.metrics.recall_score(true_y,pred_y,labels=state_list,average='weighted')))\n",
        "            print(\"f1-score {:.2f}%\".format(100*sklearn.metrics.f1_score(true_y,pred_y,labels=state_list,average='weighted')))\n",
        "            print(\"number of corrections : {}\".format(n_corrected))\n",
        "            print(\"number of added errors : {}\".format(n_added_errors))\n",
        "            print(\"total : {}\".format(total))\n",
        "            #print(sklearn.metrics.classification_report(true_y,pred_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZHySbstG_PjY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. score"
      ]
    },
    {
      "metadata": {
        "id": "80PBC0L1k_gc",
        "colab_type": "code",
        "outputId": "34c16581-b855-41aa-c4e8-0c0c31b9d0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "hmm1 = HMM1(state_list,observation_list)\n",
        "hmm1.supervised_training(train10)\n",
        "hmm1.score(test10)\n",
        "hmm1.score(test10,\"dummy\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HMM creating with: \n",
            "26 states\n",
            "26 observations\n",
            "... Supervised training ...\n",
            "=======================SCORES with viterbi========================\n",
            "error rate 6.80%\n",
            "precision 93.28%\n",
            "recall 93.20%\n",
            "f1-score 93.21%\n",
            "number of corrections : 310\n",
            "number of added errors : 63\n",
            "total : 7320\n",
            "=======================SCORES with dummy========================\n",
            "error rate 10.18%\n",
            "precision 91.79%\n",
            "recall 89.82%\n",
            "f1-score 90.50%\n",
            "number of corrections : 0\n",
            "number of added errors : 0\n",
            "total : 7320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kPUO3vW0mUxy",
        "colab_type": "code",
        "outputId": "bc05323a-b04f-444b-9332-c5ed921046d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "hmm1 = HMM1(state_list,observation_list)\n",
        "hmm1.supervised_training(train10)\n",
        "hmm1.score(test20)\n",
        "hmm1.score(test20,\"dummy\")"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HMM creating with: \n",
            "26 states\n",
            "26 observations\n",
            "... Supervised training ...\n",
            "=======================SCORES with viterbi========================\n",
            "error rate 13.23%\n",
            "precision 87.09%\n",
            "recall 86.77%\n",
            "f1-score 86.87%\n",
            "number of corrections : 1229\n",
            "number of added errors : 199\n",
            "total : 16691\n",
            "=======================SCORES with dummy========================\n",
            "error rate 19.41%\n",
            "precision 85.44%\n",
            "recall 80.59%\n",
            "f1-score 82.34%\n",
            "number of corrections : 0\n",
            "number of added errors : 0\n",
            "total : 16691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dWiQu2EZiSGV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# II - HMM d'ordre 2\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9GL4V-hzcx0m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}